# 《三国演义》智能搜索引擎系统

## 📖 项目简介

本项目为《自然语言处理》课程大作业，基于古典名著《三国演义》构建了一个支持多种检索方式的智能搜索引擎系统。系统实现了从文本预处理、文本表示到相似度计算与检索的全流程，并提供了基于 Flask 的 Web 界面，支持 TF-IDF（关键词匹配）、Word2Vec（语义相似度）及混合搜索三种查询模式。

## ✨ 主要功能

- **三种搜索模式**：
  - **TF-IDF 搜索**：基于关键词匹配
  - **Word2Vec 搜索**：基于语义相似度（采用双加权+归一化机制）
  - **混合搜索**：综合 TF-IDF 和 Word2Vec 的优势（自适应权重）
- **优化的相似度计算**：引入长度惩罚与词重叠奖励机制，有效解决短查询匹配失真问题
- **完整的预处理流程**：包括文本清洗、断句、分词、去停用词等
- **统一的预处理一致性**：确保用户查询与文档库采用完全相同的预处理流程
- **友好的 Web 界面**：基于 Flask 构建，支持实时查询与结果展示

## 🏗️ 系统架构

系统主要包含三个核心模块：

1. **预处理模块** (`Preprocess.py`) - 对《三国演义》原文进行清洗、断句、分词
2. **文本表示与模型训练模块** (`model.py`) - 训练 TF-IDF 和 Word2Vec 模型，并计算句子向量
3. **Web 搜索界面模块** (`search_engine_ui.py`) - 提供用户交互界面和搜索功能

## 📂 项目结构

```
三国演义智能搜索引擎/
├── sanguoyanyi.txt                    # 原始《三国演义》文本（需自行下载）
├── Preprocess.py                      # 文本预处理模块
├── model.py                          # 文本表示与模型训练模块
├── search_engine_ui.py               # Web 搜索界面
├── requirements.txt                   # Python 依赖包列表
├── README.md                         # 项目说明文件
│
├── sanguo_output/                    # 预处理输出目录（自动生成）
│   ├── sentences.txt                 # 分句结果
│   ├── tokens_per_sentence.txt       # 分词结果（每句一行）
│   ├── word_frequency.txt           # 词频统计
│   └── statistics.txt               # 预处理统计信息
│
└── model_output_ultimate/            # 模型输出目录（自动生成）
    ├── sanguo_tfidf_vectorizer_ultimate.pkl      # TF-IDF 向量器
    ├── sanguo_word2vec_ultimate.model           # Word2Vec 模型
    ├── sanguo_sentence_vectors_ultimate.npy     # Word2Vec 句子向量
    ├── sanguo_idf_weights_ultimate.pkl          # IDF 权重字典
    ├── sanguo_word_freq_ultimate.pkl            # 词频字典
    └── sanguo_tfidf_dense_matrix.npy            # TF-IDF 稠密矩阵
```

## 🚀 快速开始

### 1. 环境配置

确保已安装 Python 3.7+，然后安装依赖：

```bash
# 克隆项目
git clone [您的仓库地址]
cd 三国演义智能搜索引擎

# 安装依赖
pip install -r requirements.txt
```

### 2. 数据准备

从 GitHub 下载《三国演义》原文（约60万字）：

```bash
# 手动下载或使用以下链接：
# https://github.com/flowers2023/lm-LSTM/blob/master/data/sanguoyanyi.txt

# 将文件保存为项目根目录下的 sanguoyanyi.txt
```

### 3. 执行预处理

运行预处理脚本，对文本进行清洗、断句和分词：

```bash
python Preprocess.py
```

预处理结果将保存在 `sanguo_output/` 目录中。

### 4. 训练模型

运行模型训练脚本，训练 TF-IDF 和 Word2Vec 模型：

```bash
python model.py
```

训练过程包括：
- TF-IDF 特征提取（8000个特征，含一元/二元词组）
- Word2Vec 模型训练（300维向量，60轮迭代）
- 句子向量计算（IDF+词频双加权机制）
- 模型评估与可视化

训练完成后，模型文件将保存在 `model_output_ultimate/` 目录中。

### 5. 启动 Web 搜索界面

启动 Flask Web 应用：

```bash
python search_engine_ui.py
```

然后在浏览器中访问：`http://127.0.0.1:5000`

## 🖥️ 使用指南

### 系统界面操作

1. **加载模型**：
   - 首次使用时，点击"加载模型"按钮初始化系统
   - 模型加载可能需要几分钟，请耐心等待

2. **执行搜索**：
   - 在搜索框输入查询语句（如"诸葛亮草船借箭"）
   - 选择查询方式：TF-IDF、Word2Vec 或混合搜索
   - 调整返回结果数量（默认10条）
   - 可选择是否使用优化版相似度计算
   - 点击"搜索"按钮获取结果

3. **查看结果**：
   - 结果按相似度从高到低排序
   - 显示相似度百分比和进度条
   - 点击结果可查看完整句子内容
   - 混合搜索结果会显示 TF-IDF 和 Word2Vec 的子分数

### 搜索示例

系统提供以下搜索示例：
- 短查询：`诸葛亮`、`周瑜纵火`
- 中长句：`忽报张辽差人来下战书。`
- 长句：`操见树木丛杂，山川险峻，乃于马上仰面大笑不止。`

## 🔧 技术细节

### 文本预处理
- **清洗**：去除多余空格、异常标点、控制字符、网址邮箱
- **断句**：基于中文标点符号（。！？；：...）分割
- **分词**：使用 jieba 分词，添加《三国演义》专有名词词典
- **停用词**：包含文言文停用词（曰、云、道、言等）和现代停用词

### 文本表示
1. **TF-IDF**：
   - 特征范围：1-2元词组
   - 特征数量：8000个
   - 归一化：L2归一化
   - 稀疏性控制：15%-25%非零元素占比

2. **Word2Vec**：
   - 模型架构：Skip-gram
   - 向量维度：300维
   - 训练轮次：60轮
   - 窗口大小：15（适配古文长句）
   - 句子向量：IDF权重 + 词频权重 双加权平均

### 相似度计算优化
- **长度惩罚**：查询句与文档句长度差异越大，惩罚越大
- **词重叠奖励**：文档句包含查询词越多，奖励越高
- **自适应混合权重**：
  - 短查询（≤2词）：TF-IDF权重0.6，Word2Vec权重0.4
  - 中等查询（3-5词）：各0.5
  - 长查询（＞5词）：TF-IDF权重0.4，Word2Vec权重0.6

## 📊 实验效果

### 查询效果对比
- **长句查询**：效果显著，能精准匹配原文句子
- **短句查询**：通过优化机制提升准确性，但仍有挑战
- **混合搜索**：在多数场景下表现最为稳定与全面

### 性能指标
- 语料库：约60万字，处理后约1.2万个句子
- TF-IDF特征：8000维
- Word2Vec词汇表：约1.5万个词
- 搜索响应时间：通常＜0.5秒

## 🔍 核心创新点

1. **预处理一致性**：用户查询与文档库采用完全相同的预处理流程，避免特征空间不匹配问题
2. **双加权向量生成**：Word2Vec句子向量融合IDF权重与词频权重，增强核心词表达能力
3. **智能惩罚机制**：在余弦相似度基础上引入长度惩罚与词重叠奖励，有效缓解短查询句相似度失真
4. **自适应混合权重**：根据查询长度动态调整TF-IDF和Word2Vec的权重

## 🛠️ 依赖环境

```txt
Flask==2.3.3
gensim==4.3.1
jieba==0.42.1
joblib==1.3.2
matplotlib==3.7.2
numpy==1.24.3
scikit-learn==1.3.0
scipy==1.10.1
seaborn==0.12.2
```

## 📝 注意事项

1. **首次运行**：需要依次运行预处理和模型训练，过程可能需要10-20分钟
2. **内存要求**：训练Word2Vec模型需要约2GB内存
3. **文件路径**：确保 `sanguoyanyi.txt` 在项目根目录下
4. **端口占用**：Flask默认使用5000端口，如被占用请修改 `search_engine_ui.py`

## 🐛 常见问题

### Q1: 模型加载失败
**A**：检查 `model_output_ultimate/` 目录是否存在且包含所有模型文件。如缺失，请重新运行 `model.py`。

### Q2: 搜索速度慢
**A**：首次搜索会加载模型到内存，后续搜索会很快。确保系统有足够内存（建议4GB以上）。

### Q3: 短查询效果不理想
**A**：这是基于词袋和静态词向量方法的固有局限。可尝试使用优化版相似度计算。

### Q4: 如何修改查询方式权重？
**A**：在 `search_engine_ui.py` 的 `_search_hybrid` 方法中调整权重参数。

## 📄 许可信息

本项目为《自然语言处理》课程大作业，仅供学习交流使用。

## 👥 项目成员

- 卢彦竹
- 曾佳佳

## 📞 联系方式

如有问题或建议，请通过 GitHub Issues 提交。

---

## 🚀 一键启动脚本（可选）

创建 `run_all.bat`（Windows）或 `run_all.sh`（Linux/Mac）：

```bash
# Windows (run_all.bat)
@echo off
echo 正在执行《三国演义》智能搜索引擎全流程...
echo.
echo 1. 运行预处理...
python Preprocess.py
echo.
echo 2. 训练模型...
python model.py
echo.
echo 3. 启动Web界面...
python search_engine_ui.py
```

运行后系统将自动完成所有步骤并启动Web界面。

---

**开始探索《三国演义》的智能搜索之旅吧！** 🎉
